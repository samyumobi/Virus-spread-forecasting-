{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-26T17:58:49.162365Z","iopub.execute_input":"2022-01-26T17:58:49.162668Z","iopub.status.idle":"2022-01-26T17:58:49.175338Z","shell.execute_reply.started":"2022-01-26T17:58:49.162632Z","shell.execute_reply":"2022-01-26T17:58:49.174614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom plotly.offline import init_notebook_mode, iplot, plot\nimport plotly as py\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n\n# word cloud library\nfrom wordcloud import WordCloud\n\n# matplotlib\nimport matplotlib.pyplot as plt\nimport os\nprint(os.listdir(\"../input\"))","metadata":{"execution":{"iopub.status.busy":"2022-01-26T17:58:49.176924Z","iopub.execute_input":"2022-01-26T17:58:49.177341Z","iopub.status.idle":"2022-01-26T17:58:49.312894Z","shell.execute_reply.started":"2022-01-26T17:58:49.177311Z","shell.execute_reply":"2022-01-26T17:58:49.312124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/omicron-covid19-variant-daily-cases/covid-variants.csv')\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2022-01-26T17:58:49.313896Z","iopub.execute_input":"2022-01-26T17:58:49.314331Z","iopub.status.idle":"2022-01-26T17:58:49.46957Z","shell.execute_reply.started":"2022-01-26T17:58:49.314297Z","shell.execute_reply":"2022-01-26T17:58:49.468639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tracking the progression of the new omicron COVID-19 variant\nThe data\nlocation- this is the country for which the variants information is provided;\n* date - date for the data entry;\n* variant - this is the variant corresponding to this data entry;\n* num_sequences - the number of sequences processed (for the country, variant and date);\n* perc_sequences - percentage of sequences from the total number of sequences (for the country, variant and date);\n* numsequencestotal - total number of sequences (for the country, variant and date);\n","metadata":{}},{"cell_type":"code","source":"df.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-01-26T17:58:49.470731Z","iopub.execute_input":"2022-01-26T17:58:49.470983Z","iopub.status.idle":"2022-01-26T17:58:49.491011Z","shell.execute_reply.started":"2022-01-26T17:58:49.470954Z","shell.execute_reply":"2022-01-26T17:58:49.489931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Encoding categorical features\n\nFeatures that contain non numerical data like characters need to be encoded to represent data statistically. This step is performed during the data preprocessing stage.\n\n1. Label Encoding Features\n\n    * Labelling each data point in dataframe feature as number or alphabet manually using dictionaries / lists/ arrrays or using sklearn encoder.\n    * Ex: Dictionary('A':1,'B':4,'Teddy': 300, 'Valentine':598)\n\n2. One hot encoding\n\n   *  A one hot encoding is a representation of categorical variables as binary vectors.This first requires that the categorical values be mapped to integer values.Then, each integer value is represented as a binary vector that is all zero values except the index of the integer, which is marked with a 1.\n\n   * In this example, we will assume the case where you have an output sequence of the following 3 labels:\n\n            \"cold\"\n            \"warm\"\n            \"hot\"\n\n    * An example sequence of 10 time steps may be:\n\n        [cold, cold, warm, cold, hot, hot, warm, cold, warm, hot]\n\n        This would first require an integer encoding, such as 1, 2, 3. This would be followed by a one hot encoding of integers to a binary vector with 3 values, such as [1, 0, 0].\n\n        The sequence provides at least one example of every possible value in the sequence. Therefore we can use automatic methods to define the mapping of labels to integers and integers to binary vectors.\n\nRef: https://www.analyticsvidhya.com/blog/2020/08/types-of-categorical-data-encoding/\n   \n\n","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nimport seaborn as sns\nle = LabelEncoder()\ndf['loc_n'] = le.fit_transform(df['location'])\nsns.set(style = 'darkgrid')\nsns.countplot(df['loc_n'])","metadata":{"execution":{"iopub.status.busy":"2022-01-26T17:58:49.493599Z","iopub.execute_input":"2022-01-26T17:58:49.493955Z","iopub.status.idle":"2022-01-26T17:58:53.516211Z","shell.execute_reply.started":"2022-01-26T17:58:49.493912Z","shell.execute_reply":"2022-01-26T17:58:53.515402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndf['variant_n'] = le.fit_transform(df['variant'])\n","metadata":{"execution":{"iopub.status.busy":"2022-01-26T17:58:53.51763Z","iopub.execute_input":"2022-01-26T17:58:53.517884Z","iopub.status.idle":"2022-01-26T17:58:53.539822Z","shell.execute_reply.started":"2022-01-26T17:58:53.517844Z","shell.execute_reply":"2022-01-26T17:58:53.539113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature engineering\n\nIn exploratory data analysis, we often would like to analyze data by some categories. In SQL, the GROUP BY statement groups row that has the same category values into summary rows. In Pandas, SQL’s GROUP BY operation is performed using the similarly named groupby() method. Pandas’ groupby() allows us to split data into separate groups to perform computations for better analysis.\n\nRead more about feature engineering here: [Grouping data using pandas](https://towardsdatascience.com/all-pandas-groupby-you-should-know-for-grouping-data-and-performing-operations-2a8ec1327b5)","metadata":{}},{"cell_type":"code","source":"gk = df.groupby('variant')\ngk.first(5)","metadata":{"execution":{"iopub.status.busy":"2022-01-26T17:58:53.540783Z","iopub.execute_input":"2022-01-26T17:58:53.541375Z","iopub.status.idle":"2022-01-26T17:58:53.58625Z","shell.execute_reply.started":"2022-01-26T17:58:53.541335Z","shell.execute_reply":"2022-01-26T17:58:53.585268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Finding values contained in Delta group\ngk.get_group('Delta')","metadata":{"execution":{"iopub.status.busy":"2022-01-26T17:58:53.58774Z","iopub.execute_input":"2022-01-26T17:58:53.589074Z","iopub.status.idle":"2022-01-26T17:58:53.610658Z","shell.execute_reply.started":"2022-01-26T17:58:53.589035Z","shell.execute_reply":"2022-01-26T17:58:53.609787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# group by more than one category\n\ngkk = df.groupby(['variant','num_sequences_total'])\ngkk.first(5)","metadata":{"execution":{"iopub.status.busy":"2022-01-26T17:58:53.611936Z","iopub.execute_input":"2022-01-26T17:58:53.612712Z","iopub.status.idle":"2022-01-26T17:58:53.659028Z","shell.execute_reply.started":"2022-01-26T17:58:53.612675Z","shell.execute_reply":"2022-01-26T17:58:53.658096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"groupby() is a very powerful function with a lot of variations. It makes the task of splitting the dataframe over some criteria really easy and efficient.","metadata":{}},{"cell_type":"markdown","source":"# What is the count of variants in different locations ?\n\nYou call .groupby() and pass the name of the column you want to group on, which is \"location\". Then, you use [\"variant\"] to specify the columns on which you want to perform the actual aggregation.\n\n","metadata":{}},{"cell_type":"code","source":"# group by , count \n\nv_by_seq = df.groupby('location')['variant'].count()\nv_by_seq.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-01-26T17:58:53.660669Z","iopub.execute_input":"2022-01-26T17:58:53.661274Z","iopub.status.idle":"2022-01-26T17:58:53.685369Z","shell.execute_reply.started":"2022-01-26T17:58:53.661231Z","shell.execute_reply":"2022-01-26T17:58:53.684511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# using nlargest() function will get the \n# largest values of Variant sequences\ndf.groupby('variant')['perc_sequences'].nlargest().head(5)","metadata":{"execution":{"iopub.status.busy":"2022-01-26T17:58:53.687475Z","iopub.execute_input":"2022-01-26T17:58:53.687692Z","iopub.status.idle":"2022-01-26T17:58:53.71709Z","shell.execute_reply.started":"2022-01-26T17:58:53.687667Z","shell.execute_reply":"2022-01-26T17:58:53.716089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You can pass multiple parameters into groupby. Just like below","metadata":{}},{"cell_type":"markdown","source":"# Distribution of different Variants \n","metadata":{}},{"cell_type":"code","source":"# Distribution of different Variants \ndf.groupby('variant',sort=False).sum()","metadata":{"execution":{"iopub.status.busy":"2022-01-26T17:58:53.718008Z","iopub.execute_input":"2022-01-26T17:58:53.71859Z","iopub.status.idle":"2022-01-26T17:58:53.751473Z","shell.execute_reply.started":"2022-01-26T17:58:53.718557Z","shell.execute_reply":"2022-01-26T17:58:53.750797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.groupby(['location','perc_sequences'])['variant'].count()","metadata":{"execution":{"iopub.status.busy":"2022-01-26T17:58:53.752469Z","iopub.execute_input":"2022-01-26T17:58:53.753253Z","iopub.status.idle":"2022-01-26T17:58:53.78557Z","shell.execute_reply.started":"2022-01-26T17:58:53.753221Z","shell.execute_reply":"2022-01-26T17:58:53.784816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Line Chart","metadata":{}},{"cell_type":"code","source":"\n\nimport plotly.graph_objs as g\nl = df.iloc[:200,:]\ns = g.Scatter(x = l.variant, y = l.perc_sequences,\n             mode = 'lines+markers',name = 'Variants',\n             text = l.variant,fillcolor = 'red')\n\n\ndata = [s]\nlayout = dict(title = 'Percentage of Variants')\nfig = dict(data = data, layout = layout)\niplot(fig)","metadata":{"execution":{"iopub.status.busy":"2022-01-26T18:18:44.747118Z","iopub.execute_input":"2022-01-26T18:18:44.747411Z","iopub.status.idle":"2022-01-26T18:18:44.7822Z","shell.execute_reply.started":"2022-01-26T18:18:44.747375Z","shell.execute_reply":"2022-01-26T18:18:44.781309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Observation:\n\n1. The percentage of Delta and other viruses have sharp increase.\n2. The S pelican variant cases would be third highest virus variant, which would spread faster.\n","metadata":{}},{"cell_type":"markdown","source":"# Bar Charts","metadata":{}},{"cell_type":"markdown","source":"Virus spread across the years","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ndf['year'] = pd.DatetimeIndex(df['date']).year\ndf['month'] = pd.DatetimeIndex(df['date']).month\ndf['day'] = pd.DatetimeIndex(df['date']).day\n\nprint('Years in dataset',np.unique(df['year']))\nsns.set()\ndf['year'].plot()\nplt.xlabel('Cases')\nplt.ylabel('Year')\nplt.title('Virus spread across the years')","metadata":{"execution":{"iopub.status.busy":"2022-01-26T18:58:10.821085Z","iopub.execute_input":"2022-01-26T18:58:10.821356Z","iopub.status.idle":"2022-01-26T18:58:11.141216Z","shell.execute_reply.started":"2022-01-26T18:58:10.821324Z","shell.execute_reply":"2022-01-26T18:58:11.140289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Observation:\n\n* The number of cases increases very fast across equal time periods during 2020, 2021. \n* In 2022 and 2021, the virus spreads rapidly only during certain time periods. The virus impact is not same in all months.","metadata":{}},{"cell_type":"code","source":"# Consider data from 2021\ndf2021 = df[df.year==2020].iloc[:100,:]\nb1 = g.Bar(x = df2021.variant, y = df.perc_sequences,\n          name = 'Variant Percentage Sequences',\n           marker = dict(color = 'rgba(255, 174, 255, 0.5)',\n        line=dict(color='rgb(0,0,0)',width=1.5)))\nb2 = g.Bar(x = df2021.variant, y = df.num_sequences_total,\n          name = 'Variant total sequences',\n          marker = dict(color = 'rgba(255, 255, 128, 0.5)',\n                              line=dict(color='rgb(0,0,0)',width=1.5)))\ndata = [b1,b2]\nlayout = g.Layout(barmode = 'group')\nfig = g.Figure(data = data, layout = layout)\niplot(fig)","metadata":{"execution":{"iopub.status.busy":"2022-01-26T19:00:40.557364Z","iopub.execute_input":"2022-01-26T19:00:40.558008Z","iopub.status.idle":"2022-01-26T19:00:40.678291Z","shell.execute_reply.started":"2022-01-26T19:00:40.557939Z","shell.execute_reply":"2022-01-26T19:00:40.677552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" \n<span style=\"color:blue;font-size:2em;\">*Let's create some 3D plots that allow us to view data in multi dimensional space..*; </span>\n\n<font size = \"4\"><br>🪄🛑 🪄 🛑 🪄🛑  *1, 2, 3, ...... Ta da Exploring Plotly * 🪄🛑 🪄🛑 🪄🛑 </font>\n\n<img src = 'https://media.giphy.com/media/26FPAn6hPp6Fqx7qw/giphy.gif'>","metadata":{}},{"cell_type":"markdown","source":"# 3D Plots\n\nLocation wise cases spread","metadata":{}},{"cell_type":"code","source":"import plotly.express as px\n\n# Location wise cases spread\nfig = px.scatter_3d(df, x='location', y='perc_sequences', z = 'num_sequences_total' , \n                   color = 'location')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-26T19:04:21.701388Z","iopub.execute_input":"2022-01-26T19:04:21.701716Z","iopub.status.idle":"2022-01-26T19:04:22.847745Z","shell.execute_reply.started":"2022-01-26T19:04:21.701681Z","shell.execute_reply":"2022-01-26T19:04:22.84689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.scatter_3d(df, x='variant', y='perc_sequences', z = 'variant_n' , \n                   color = 'variant',symbol = 'variant')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-26T19:09:20.914431Z","iopub.execute_input":"2022-01-26T19:09:20.914744Z","iopub.status.idle":"2022-01-26T19:09:21.744924Z","shell.execute_reply.started":"2022-01-26T19:09:20.914711Z","shell.execute_reply":"2022-01-26T19:09:21.744012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3D Surface plots\n\nVirus spread","metadata":{}},{"cell_type":"code","source":"v_data = df.groupby('variant',sort=False).sum()\n\nv_data.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-01-26T19:16:40.172243Z","iopub.execute_input":"2022-01-26T19:16:40.172547Z","iopub.status.idle":"2022-01-26T19:16:40.203161Z","shell.execute_reply.started":"2022-01-26T19:16:40.172504Z","shell.execute_reply":"2022-01-26T19:16:40.202411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = g.Figure(data = [g.Surface(z = v_data.values)])\nfig.update_traces(contours_z=dict(show=True, usecolormap=True,\n                                  highlightcolor=\"limegreen\", project_z=True))\nfig.update_layout(title = 'Variants 3D surface plot',autosize=True,\n                 width = 600, height = 800,\n                 margin = dict(l = 65, r=50, b=65, t=90))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-26T19:18:31.552827Z","iopub.execute_input":"2022-01-26T19:18:31.55314Z","iopub.status.idle":"2022-01-26T19:18:31.591655Z","shell.execute_reply.started":"2022-01-26T19:18:31.553112Z","shell.execute_reply":"2022-01-26T19:18:31.590892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3D line plots","metadata":{}},{"cell_type":"markdown","source":"Spread of virus from 2020 to 2022","metadata":{}},{"cell_type":"code","source":"import plotly.graph_objects as go\nimport pandas as pd\nimport numpy as np\n\nrs = np.random.RandomState()\nrs.seed(0)\n\ndef brownian_motion(T = 1, N = 100, mu = 0.1, sigma = 0.01, S0 = 20):\n    dt = float(T)/N\n    t = np.linspace(0, T, N)\n    W = rs.standard_normal(size = N)\n    W = np.cumsum(W)*np.sqrt(dt) # standard brownian motion\n    X = (mu-0.5*sigma**2)*t + sigma*W\n    S = S0*np.exp(X) # geometric brownian motion\n    return S\n\ndates = pd.date_range(l.date.min(), l.date.max())\nT = (dates.max()-dates.min()).days / 365\nN = dates.size\nstart_price = 100\ny = brownian_motion(T, N, sigma=0.1, S0=start_price)\nz = brownian_motion(T, N, sigma=0.1, S0=start_price)\n\nfig = go.Figure(data=go.Scatter3d(\n    x=dates, y=y, z=z,\n    marker=dict(\n        size=4,\n        color=z,\n        colorscale='Viridis',\n    ),\n    line=dict(\n        color='darkblue',\n        width=2\n    )\n))\n\nfig.update_layout(\n    width=800,\n    height=700,\n    autosize=False,\n    scene=dict(\n        camera=dict(\n            up=dict(\n                x=0,\n                y=0,\n                z=1\n            ),\n            eye=dict(\n                x=0,\n                y=1.0707,\n                z=1,\n            )\n        ),\n        aspectratio = dict( x=1, y=1, z=0.7 ),\n        aspectmode = 'manual'\n    ),\n)\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-26T19:30:23.214699Z","iopub.execute_input":"2022-01-26T19:30:23.21513Z","iopub.status.idle":"2022-01-26T19:30:23.256356Z","shell.execute_reply.started":"2022-01-26T19:30:23.215086Z","shell.execute_reply":"2022-01-26T19:30:23.255397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n<img src=\"https://media.giphy.com/media/kfR5iyQgmq7PoiFTAf/giphy.gif\">","metadata":{}},{"cell_type":"markdown","source":"# Upvote\n\n<img src='https://media.giphy.com/media/wKzqKQt1Xhyv069mmY/giphy.gif'>\n\nHey Kaggler !! If you liked my notebook. Please upvote. \n\n","metadata":{}}]}